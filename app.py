"""app.py
æœ€å°å¯è¿è¡Œçš„ Streamlit åº”ç”¨ï¼š
- é€‰æ‹©èµ·å§‹å›¾ç‰‡æˆ–è¾“å…¥ä¸»é¢˜
- ç”Ÿæˆå¼€ç¯‡ â†’ çº¿ç´¢æå– â†’ å‘é‡æ£€ç´¢ â†’ ç»­å†™ï¼Œç›´è‡³è¾¾åˆ°ç›®æ ‡æ®µæ•°
- æ— å‘é‡åº“æˆ–æ— åŒ¹é…æ—¶ï¼Œé‡‡ç”¨å›é€€ç­–ç•¥ç»§ç»­æ–‡æœ¬ç”Ÿæˆ
"""
from __future__ import annotations

import json
from typing import List, Optional, Set, Tuple

import streamlit as st
from PIL import Image

from prompts import (
    SYSTEM_CLUE_EXTRACTOR,
    SYSTEM_STORY_WRITER,
    USER_CLUE_TEMPLATE,
    USER_CONTINUE_TEMPLATE,
    USER_OPENING_TEMPLATE,
    USER_IMAGE_SELECTION_TEMPLATE,
    USER_SEQUENCE_SELECTION_TEMPLATE,
    USER_PARAGRAPH_FROM_IMAGE_TEMPLATE,
)
from utils import (
    EmbeddingService,
    LLMClient,
    get_candidate_images,
    get_random_candidate_images,
    get_or_create_collection,
    list_image_paths,
    load_config,
    query_similar_documents,
    safe_open_image,
)


st.set_page_config(page_title="AI æ•…äº‹ç¼–ç»‡è€…", page_icon="ğŸ“–", layout="wide")

cfg = load_config()
llm = LLMClient(cfg)
emb = EmbeddingService(cfg.embedding_model_name)
collection = get_or_create_collection(cfg.chroma_persist_dir, name="images")


def extract_clues(paragraph: str) -> List[str]:
    """ä»æ®µè½ç»“å°¾æå– 1-3 ä¸ªå…³é”®è¯ï¼Œç”¨äºæ£€ç´¢ä¸‹ä¸€å¼ å›¾ç‰‡ã€‚"""
    prompt = USER_CLUE_TEMPLATE.format(paragraph=paragraph)
    text = llm.chat(SYSTEM_CLUE_EXTRACTOR, prompt).strip()
    try:
        arr = json.loads(text)
        if isinstance(arr, list):
            return [str(x) for x in arr][:3]
    except Exception:
        pass
    # å›é€€ï¼šå–æœ€åä¸€å¥ä¸­çš„åè¯æ ·å¼è¯ï¼ˆç®€å•è¿‘ä¼¼ï¼‰
    last = paragraph.split("ã€‚")[-2:]  # å–æœ«å°¾å¥å­ç‰‡æ®µ
    fallback = "ï¼Œ".join(last).strip()
    return [fallback[:16]] if fallback else ["çº¿ç´¢"]


def gen_opening(input_hint: str) -> str:
    user = USER_OPENING_TEMPLATE.format(input_hint=input_hint)
    return llm.chat(SYSTEM_STORY_WRITER, user).strip()


def gen_continuation(prev_paragraph: str, image_description: str) -> str:
    user = USER_CONTINUE_TEMPLATE.format(
        prev_paragraph=prev_paragraph, image_description=image_description
    )
    return llm.chat(SYSTEM_STORY_WRITER, user).strip()


def select_image_sequence(story_theme: str, target_length: int, n_candidates: int = 20) -> List[Tuple[str, dict]]:
    """é€‰æ‹©å®Œæ•´çš„å›¾ç‰‡åºåˆ—ï¼Œè®© LLM ä»å€™é€‰ä¸­é€‰æ‹©ç¬¦åˆæ•…äº‹ç»“æ„çš„åºåˆ—ã€‚"""
    # éšæœºè·å–æ›´å¤šå€™é€‰å›¾ç‰‡
    candidates = get_random_candidate_images(collection, n_candidates=n_candidates, used_paths=set())
    if not candidates:
        return []
    
    # æ„é€ å€™é€‰å›¾ç‰‡æè¿°
    candidate_descriptions = []
    for i, (doc, meta) in enumerate(candidates, 1):
        filename = meta.get("filename", "unknown")
        candidate_descriptions.append(f"{i}. {filename}: {doc}")
    
    candidate_text = "\n".join(candidate_descriptions)
    
    # è®© LLM é€‰æ‹©å›¾ç‰‡åºåˆ—
    selection_prompt = USER_SEQUENCE_SELECTION_TEMPLATE.format(
        story_theme=story_theme,
        target_length=target_length,
        candidate_images=candidate_text
    )
    
    try:
        selection = llm.chat(SYSTEM_STORY_WRITER, selection_prompt).strip()
        # è§£æé€‰æ‹©çš„ç¼–å·åºåˆ—
        indices = [int(x.strip()) - 1 for x in selection.split(",")]
        selected_sequence = []
        for idx in indices:
            if 0 <= idx < len(candidates):
                selected_sequence.append(candidates[idx])
        
        # ç¡®ä¿åºåˆ—é•¿åº¦ç¬¦åˆè¦æ±‚
        if len(selected_sequence) == target_length:
            return selected_sequence
    except (ValueError, IndexError):
        pass
    
    # å›é€€ï¼šè¿”å›å‰ target_length ä¸ªå€™é€‰
    return candidates[:target_length] if len(candidates) >= target_length else candidates


def generate_paragraph_for_image(story_context: str, paragraph_index: int, total_paragraphs: int, 
                                image_description: str, previous_paragraph: str = "", 
                                previous_paragraphs: List[str] = None) -> str:
    """åŸºäºæŒ‡å®šå›¾ç‰‡ç”Ÿæˆå¯¹åº”çš„æ•…äº‹æ®µè½ã€‚"""
    if previous_paragraphs is None:
        previous_paragraphs = []
    
    prompt = USER_PARAGRAPH_FROM_IMAGE_TEMPLATE.format(
        story_context=story_context,
        paragraph_index=paragraph_index,
        total_paragraphs=total_paragraphs,
        image_description=image_description,
        previous_paragraph=previous_paragraph or "ï¼ˆè¿™æ˜¯å¼€ç¯‡ï¼‰"
    )
    
    max_retries = 3
    for attempt in range(max_retries):
        # é™åˆ¶ç”Ÿæˆé•¿åº¦ï¼Œé˜²æ­¢é‡å¤
        paragraph = llm.chat(SYSTEM_STORY_WRITER, prompt, max_tokens=400).strip()
        
        # æ£€æµ‹æ®µè½å†…é‡å¤
        if _has_repetitive_content(paragraph):
            st.warning(f"ç¬¬{paragraph_index}æ®µæ£€æµ‹åˆ°å†…éƒ¨é‡å¤ï¼ˆå°è¯•{attempt+1}/{max_retries}ï¼‰")
            continue
        
        # æ£€æµ‹ä¸ä¹‹å‰æ®µè½çš„é‡å¤
        if _is_similar_to_previous(paragraph, previous_paragraphs):
            st.warning(f"ç¬¬{paragraph_index}æ®µä¸å‰é¢æ®µè½é‡å¤ï¼ˆå°è¯•{attempt+1}/{max_retries}ï¼‰")
            # æ·»åŠ æ›´å¼ºçš„åé‡å¤æç¤º
            prompt += f"\n\né‡è¦æé†’ï¼šè¿™ä¸€æ®µå¿…é¡»ä¸å‰é¢çš„å†…å®¹å®Œå…¨ä¸åŒï¼Œè¦åŸºäºæ–°çš„å›¾ç‰‡æè¿°åˆ›ä½œå…¨æ–°çš„æƒ…èŠ‚ã€‚"
            continue
        
        # å¦‚æœé€šè¿‡æ‰€æœ‰æ£€æµ‹ï¼Œè¿”å›ç»“æœ
        return paragraph
    
    # å¦‚æœå¤šæ¬¡é‡è¯•éƒ½å¤±è´¥ï¼Œä½¿ç”¨æœ€ä¸¥æ ¼çš„æç¤ºé‡æ–°ç”Ÿæˆ
    st.error(f"ç¬¬{paragraph_index}æ®µå¤šæ¬¡ç”Ÿæˆé‡å¤ï¼Œä½¿ç”¨ä¸¥æ ¼æ¨¡å¼é‡æ–°ç”Ÿæˆ...")
    strict_prompt = f"""åŸºäºå›¾ç‰‡æè¿°åˆ›ä½œæ•…äº‹æ®µè½ï¼š
å›¾ç‰‡æè¿°ï¼š{image_description}
æ®µè½ä½ç½®ï¼šç¬¬{paragraph_index}æ®µï¼ˆå…±{total_paragraphs}æ®µï¼‰
ä¸Šä¸€æ®µï¼š{previous_paragraph or "ï¼ˆå¼€ç¯‡ï¼‰"}

è¦æ±‚ï¼š
1. ä¸¥æ ¼åŸºäºå½“å‰å›¾ç‰‡å†…å®¹åˆ›ä½œï¼Œä¸è¦é‡å¤ä¹‹å‰çš„æƒ…èŠ‚
2. ä¸ä¸Šä¸€æ®µè‡ªç„¶è¡”æ¥ä½†æƒ…èŠ‚è¦æœ‰æ–°å‘å±•
3. 150-200å­—ï¼Œè¯­è¨€ç®€æ´
4. ç»å¯¹ä¸èƒ½é‡å¤ä¹‹å‰å‡ºç°è¿‡çš„å¯¹è¯æˆ–æè¿°

ç›´æ¥è¾“å‡ºæ•…äº‹æ®µè½ï¼š"""
    
    return llm.chat(SYSTEM_STORY_WRITER, strict_prompt, max_tokens=300).strip()


def _has_repetitive_content(text: str, threshold: int = 3) -> bool:
    """æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦æœ‰é‡å¤çš„å¥å­æˆ–æ®µè½ã€‚"""
    sentences = [s.strip() for s in text.split('ã€‚') if s.strip()]
    if len(sentences) < threshold:
        return False
    
    # æ£€æŸ¥ç›¸åŒå¥å­å‡ºç°æ¬¡æ•°
    sentence_counts = {}
    for sentence in sentences:
        if len(sentence) > 10:  # åªæ£€æŸ¥è¾ƒé•¿çš„å¥å­
            sentence_counts[sentence] = sentence_counts.get(sentence, 0) + 1
    
    # å¦‚æœä»»ä½•å¥å­å‡ºç°è¶…è¿‡2æ¬¡ï¼Œè®¤ä¸ºæ˜¯é‡å¤
    return any(count >= threshold for count in sentence_counts.values())


def _is_similar_to_previous(current_paragraph: str, previous_paragraphs: List[str], similarity_threshold: float = 0.7) -> bool:
    """æ£€æµ‹å½“å‰æ®µè½æ˜¯å¦ä¸ä¹‹å‰çš„æ®µè½è¿‡äºç›¸ä¼¼ã€‚"""
    if not previous_paragraphs:
        return False
    
    # å°†æ®µè½åˆ†è§£ä¸ºå¥å­
    current_sentences = set(s.strip() for s in current_paragraph.split('ã€‚') if s.strip() and len(s.strip()) > 5)
    
    for prev_paragraph in previous_paragraphs:
        prev_sentences = set(s.strip() for s in prev_paragraph.split('ã€‚') if s.strip() and len(s.strip()) > 5)
        
        # è®¡ç®—å¥å­é‡å åº¦
        if current_sentences and prev_sentences:
            overlap = len(current_sentences.intersection(prev_sentences))
            total_unique = len(current_sentences.union(prev_sentences))
            
            if total_unique > 0:
                similarity = overlap / total_unique
                if similarity > similarity_threshold:
                    return True
    
    return False


# ----------------------------
# UI
# ----------------------------

st.title("ğŸ“– AI æ•…äº‹ç¼–ç»‡è€…")

with st.sidebar:
    st.header("è®¾ç½®")
    images = list_image_paths(cfg.image_dir)
    image_names = [p.name for p in images]
    start_mode = st.radio("é€‰æ‹©å¼€ç«¯æ–¹å¼", ["é€‰æ‹©èµ·å§‹å›¾ç‰‡", "è¾“å…¥ä¸»é¢˜"], index=0)

    start_image_name = None
    start_topic = None
    if start_mode == "é€‰æ‹©èµ·å§‹å›¾ç‰‡":
        start_image_name = st.selectbox("èµ·å§‹å›¾ç‰‡", options=["(ä¸é€‰)"] + image_names, index=0)
    else:
        start_topic = st.text_input("æ•…äº‹ä¸»é¢˜", placeholder="ä¾‹å¦‚ï¼šé›¨åçš„åŸå¸‚ã€é—å¤±çš„è½¦ç¥¨â€¦â€¦")

    target_len = st.number_input("ç›®æ ‡æ®µè½æ•°", min_value=3, max_value=12, value=cfg.story_target_length, step=1)
    run = st.button("å¼€å§‹ç”Ÿæˆ", type="primary")

col_left, col_right = st.columns([1, 1])

# å±•ç¤ºå›¾ç‰‡åº“é¢„è§ˆ
with col_left:
    st.subheader("å›¾ç‰‡åº“é¢„è§ˆ")
    if images:
        thumbs = images[:8]
        for p in thumbs:
            img = safe_open_image(p)
            if img is not None:
                st.image(img, caption=p.name, use_container_width=True)
    else:
        st.info("è¯·å°†å›¾ç‰‡æ”¾å…¥ç›®å½•ï¼š" + cfg.image_dir)

# æ•…äº‹ç”ŸæˆåŒºåŸŸ
with col_right:
    st.subheader("ç”Ÿæˆç»“æœ")
    if run:
        # ç¡®å®šæ•…äº‹ä¸»é¢˜
        if start_mode == "é€‰æ‹©èµ·å§‹å›¾ç‰‡" and start_image_name and start_image_name != "(ä¸é€‰)":
            story_theme = f"ä»¥å›¾ç‰‡'{start_image_name}'ä¸ºå¼€ç«¯çš„æ•…äº‹"
        else:
            story_theme = start_topic or "ä¸€ä¸ªæ™®é€šä½†ä¸å¹³å‡¡çš„å¤œæ™š"
        
        st.write(f"ğŸ“– æ•…äº‹ä¸»é¢˜ï¼š{story_theme}")
        st.write(f"ğŸ“ ç›®æ ‡é•¿åº¦ï¼š{target_len}æ®µ")
        
        # ç¬¬ä¸€æ­¥ï¼šé€‰æ‹©å®Œæ•´çš„å›¾ç‰‡åºåˆ—
        with st.spinner("ğŸ¯ æ­£åœ¨é€‰æ‹©å›¾ç‰‡åºåˆ—..."):
            image_sequence = select_image_sequence(story_theme, int(target_len))
        
        if not image_sequence:
            st.error("âŒ æ— æ³•è·å–è¶³å¤Ÿçš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡åº“")
            st.stop()
        
        st.success(f"âœ… å·²é€‰æ‹© {len(image_sequence)} å¼ å›¾ç‰‡")
        
        # æ˜¾ç¤ºé€‰ä¸­çš„å›¾ç‰‡åºåˆ—
        with st.expander("ğŸ–¼ï¸ æŸ¥çœ‹é€‰ä¸­çš„å›¾ç‰‡åºåˆ—"):
            cols = st.columns(min(len(image_sequence), 4))
            for i, (doc, meta) in enumerate(image_sequence):
                with cols[i % 4]:
                    try:
                        img_path = meta.get("path")
                        if img_path:
                            st.image(Image.open(img_path), caption=f"{i+1}. {meta.get('filename', 'unknown')}", use_container_width=True)
                        st.caption(doc[:100] + "..." if len(doc) > 100 else doc)
                    except Exception:
                        st.caption(f"{i+1}. {meta.get('filename', 'unknown')}")
        
        # ç¬¬äºŒæ­¥ï¼šåŸºäºå›¾ç‰‡åºåˆ—ç”Ÿæˆå¯¹åº”çš„æ•…äº‹æ®µè½
        story: List[Tuple[str, Optional[str]]] = []  # (paragraph, image_path)
        
        with st.spinner("âœï¸ æ­£åœ¨ç”Ÿæˆæ•…äº‹..."):
            for i, (doc, meta) in enumerate(image_sequence, 1):
                # ç”Ÿæˆå½“å‰æ®µè½
                previous_paragraph = story[-1][0] if story else ""
                previous_paragraphs = [p[0] for p in story]  # è·å–ä¹‹å‰æ‰€æœ‰æ®µè½
                
                paragraph = generate_paragraph_for_image(
                    story_context=story_theme,
                    paragraph_index=i,
                    total_paragraphs=len(image_sequence),
                    image_description=doc,
                    previous_paragraph=previous_paragraph,
                    previous_paragraphs=previous_paragraphs
                )
                
                image_path = meta.get("path")
                story.append((paragraph, image_path))
                
                # æ˜¾ç¤ºç”Ÿæˆè¿›åº¦
                st.write(f"âœ… ç¬¬ {i} æ®µå·²ç”Ÿæˆ")

        # å±•ç¤ºç»“æœ
        for idx, (para, img_path) in enumerate(story, 1):
            st.markdown(f"**ç¬¬ {idx} æ®µ**")
            if img_path:
                try:
                    st.image(Image.open(img_path), use_container_width=True)
                except Exception:
                    st.caption(f"[å›¾ç‰‡æ— æ³•æ˜¾ç¤º] {img_path}")
            st.write(para)
            st.divider()

        # å¯¼å‡ºï¼ˆç®€å•ï¼‰
        if st.download_button(
            label="å¯¼å‡º Markdown",
            data="\n\n".join([p for p, _ in story]).encode("utf-8"),
            file_name="story.md",
            mime="text/markdown",
        ):
            st.toast("å·²å¯¼å‡º story.md") 